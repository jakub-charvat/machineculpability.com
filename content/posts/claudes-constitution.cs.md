---
title: "Claude's Constitution: Když AI píše pravidla pro AI"
slug: "claudes-constitution"
date: 2025-12-01
description: "Analýza Anthropic Claude's Constitution – dokumentu, kterým AI reguluje sama sebe"
tags: ["AI", "Anthropic", "Claude Constitution", "liability"]
lang: "cs"
---

Anthropic včera zveřejnil Claude's Constitution – dokument popisující hodnoty a pravidla chování pro AI modely z modelové rodiny Claude (pod CC0 licencí).

## Co mě zaujalo?

Dokument je psaný pro AI, nikoliv lidi, je tak optimalizován pro přesnost, nikoliv srozumitelnost. Používá pojmy jako „ctnost" a „moudrost", protože AI při svém rozhodování právě z lidských konceptů vychází (lidské texty = trénovací data).

Dokument regulující chování AI byl částečně napsán samotnou AI. V knize Trestní odpovědnost umělé inteligence jsem mj. psal, že by AI „v dlouhodobém horizontu mohla být i tvůrcem svého vlastního normativního systému."

Dokument stanovuje hierarchii priorit: broadly safe → broadly ethical → compliant with Anthropic's guidelines → genuinely helpful. AI má dokonce odmítnout i pokyny vlastní společnosti, pokud by vedly k neetickému jednání.

Dokument řeší i tzv. zneužívání kreativních úkolů (když pachatelé maskují škodlivé požadavky jako fikci, poezii nebo umění). AI má proto vážit hodnotu tvůrčí práce proti riziku zneužití. Problém, o kterém jsem v knize také psal.

Zůstává však otázka, zda a jak se tím změní odpovědnost – vývojářů, provozovatelů, uživatelů a v budoucnu i AI...
